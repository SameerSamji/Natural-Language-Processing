{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc1e39e9-d0b4-4555-8614-cb59e453a1f8",
   "metadata": {},
   "source": [
    "# Exercise Contextualized Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840a5dc7-915f-4af9-a62f-5b4dbf33b080",
   "metadata": {},
   "source": [
    "### Load the dataset of movie lines which we used in the exercise last week"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076ed804-6f99-4e3a-bbba-b47da46f28ac",
   "metadata": {},
   "source": [
    "##### Extracting the movie lines dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e22247-88f1-4316-bb4c-dabd2870eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b96f5f6-5bc0-4de3-9943-68aaa02b9ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile('movie_lines.tsv.zip', 'r') as zipObj:\n",
    "    zipObj.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dd5c90-774c-478d-a81c-6b64bbf7b260",
   "metadata": {},
   "source": [
    "##### Extracting the movie lines and saving it into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74d852c1-78d7-4a53-a4a1-90e8391f935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_lines = []\n",
    "for line in open('movie_lines.tsv', encoding='utf8'):\n",
    "    line = line.strip()\n",
    "    while line[0] == '\"' and line[-1] == '\"':\n",
    "        line = line[1:-1]\n",
    "    movie_lines.append(line.split('\\t')[-1])\n",
    "movie_lines = [l.replace('\"\"', '\"').replace(' ', ' ') for l in movie_lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11216c5-1360-497f-9a06-3b119df35eb7",
   "metadata": {},
   "source": [
    "##### Tokenzing the sentences and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066c5fa9-5558-4c80-a19a-287af5802ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer(preserve_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d25553b-b1f4-4f5d-88f7-dc5c2248825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for line in movie_lines:\n",
    "    line_sents = sent_tokenize(line)\n",
    "    for sent in line_sents:\n",
    "        sentences.append(tokenizer.tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7766654-bf78-4e1c-913a-af4f27b870f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "words = Counter(c for clist in sentences for c in clist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70efd9c-bc61-4b7d-bfa0-baaacc78e9d1",
   "metadata": {},
   "source": [
    "### Select (at least) two words which occur at least 100 times in this dataset. One word should have only one meaning. The other word should have (very many) multiple meanings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97e11d1-a28c-43d0-816b-dc681a360110",
   "metadata": {},
   "source": [
    "##### Selecting two words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5660a67-2773-4cc8-b19d-9fde7c67df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_meaning_word = 'date'\n",
    "one_meaning_word = 'king'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be3cdbc-a730-4eb8-a5e0-52aa21df6f58",
   "metadata": {},
   "source": [
    "##### Counting how often the word occurs in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3786cc7-6d3e-489a-9ae2-ab985c6f7f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word with multiple meaning: 'date', and has frequency in the dataset: 371\n",
      "The word with only one meaning: 'king', and has frequency in the dataset: 457\n"
     ]
    }
   ],
   "source": [
    "print('The word with multiple meaning: \\'{}\\', and has frequency in the dataset: {}'.format(multiple_meaning_word, words.get(multiple_meaning_word)))\n",
    "print('The word with only one meaning: \\'{}\\', and has frequency in the dataset: {}'.format(one_meaning_word, words.get(one_meaning_word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dffb21-3660-4f8e-8ef8-aee8e37be35e",
   "metadata": {},
   "source": [
    "### Compute the flair representations for all sentences where the word occurs in. From each of those sentence representations select the contextualized embedding vector of the word and save all these vectors in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67598252-2489-41af-91dc-578e810e4745",
   "metadata": {},
   "source": [
    "##### Separating sentences for each word and saving it in a separate list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a7837d8-ab41-494d-b349-a5243f5e9a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_multiple_word = []\n",
    "sentences_one_word = []\n",
    "for sent in sentences:\n",
    "    if multiple_meaning_word in sent:\n",
    "        sentences_multiple_word.append(sent)\n",
    "    elif one_meaning_word in sent:\n",
    "        sentences_one_word.append(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a055b27-8252-4483-92ce-300fb768c440",
   "metadata": {},
   "source": [
    "##### Calculating the Contextualized embedding of a word in each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35ad1682-8e50-4b6f-b03b-1937b1d73525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
    "from flair.data import Sentence\n",
    "\n",
    "def contextualized_embedding(word, sentences):\n",
    "    embedding_vectors = []\n",
    "    stacked_embeddings = StackedEmbeddings([\n",
    "                                        WordEmbeddings('glove'),\n",
    "                                        FlairEmbeddings('news-forward'),\n",
    "                                        FlairEmbeddings('news-backward'),\n",
    "                                       ])\n",
    "    for sent in sentences:\n",
    "        sentence = Sentence(' '.join(sent))\n",
    "        stacked_embeddings.embed(sentence)\n",
    "        for token in sentence:\n",
    "            if token.text == word:\n",
    "                embedding_vectors.append(token.embedding.cpu().detach().numpy())\n",
    "    \n",
    "    return np.array(embedding_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ab967a8-8194-4a1e-bd20-d72ed8151d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_embedding_vector = contextualized_embedding(multiple_meaning_word, sentences_multiple_word)\n",
    "one_embedding_vector = contextualized_embedding(one_meaning_word, sentences_one_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3159e9d-6233-407a-8f90-cc3a916fb641",
   "metadata": {},
   "source": [
    "### Compute a centroid embedding vector for all contextualized embeddings of the word (compute the element-wise sum of all vectors and devide by the number of vectors - the resulting centroid vector is a vector in the same embedding space). Calculate the standard deviation of the cosine similarities of the contextualized embedding vectors to the centroid vector?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf62d14-702d-469c-b339-e9f164236b6c",
   "metadata": {},
   "source": [
    "##### Computing the centroid embedding vector for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33924771-50a1-41b2-a974-c828d6103f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_centroid_vector(vectors):\n",
    "    centroid = np.zeros(shape=(vectors[0].shape))\n",
    "    for vec in vectors:\n",
    "        centroid += vec\n",
    "    return centroid / len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06a2d099-dd34-43eb-98cc-59c52929c94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_word_centroid = compute_centroid_vector(multiple_embedding_vector)\n",
    "one_word_centroid = compute_centroid_vector(one_embedding_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ab9290-5ad5-4d27-b91c-0810c5c90705",
   "metadata": {},
   "source": [
    "##### Calculating the Standard deviation of the cosine similarity between each vector and the centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27eb11d3-e535-4e4f-9dbe-459b59972780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "def compute_cosine_similarity(vectors, centroid):\n",
    "    cosine_similarities = []\n",
    "    for vect in vectors:\n",
    "        cosine_similarities.append(1 - spatial.distance.cosine(vect, centroid))\n",
    "    return np.array(cosine_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4b27f39-af3a-48c6-9ecd-24f97496e145",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_word_std = np.std(compute_cosine_similarity(multiple_embedding_vector, multiple_word_centroid))\n",
    "one_word_std = np.std(compute_cosine_similarity(one_embedding_vector, one_word_centroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d259caf-a28c-465d-9a49-4da5fa9ad83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: date, with MULTIPLE meanings based on context:\n",
      "Standard deviation of the cosine similarities of the contextualized embedding vectors to the centroid vector: 0.033\n",
      "\n",
      "\n",
      "Word: king, with ONE meaning in whole context\n",
      "Standard deviation of the cosine similarities of the contextualized embedding vectors to the centroid vector: 0.018\n"
     ]
    }
   ],
   "source": [
    "print('Word: {}, with MULTIPLE meanings based on context:'.format(multiple_meaning_word))\n",
    "print('Standard deviation of the cosine similarities of the contextualized embedding vectors to the centroid vector: {:.02}'.format(multiple_word_std))\n",
    "\n",
    "print('\\n\\nWord: {}, with ONE meaning in whole context'.format(one_meaning_word))\n",
    "print('Standard deviation of the cosine similarities of the contextualized embedding vectors to the centroid vector: {:.02}'.format(one_word_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae9fb87-7593-4e78-8a1d-2f2bd6fdba5e",
   "metadata": {},
   "source": [
    "It can be observe from the results above that the standard deviation of the word with one meaning only is very close to its centroid whereas on the otherhand, the word with multiple meanings in different context was a bit far from the centroid as compared to the other word."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
